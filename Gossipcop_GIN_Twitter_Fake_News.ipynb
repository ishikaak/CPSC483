{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### GIN implementation for Fake News Detection on Gossipcop dataset\n",
        "\n",
        "> Indented block\n",
        "\n"
      ],
      "metadata": {
        "id": "DwRMdI3yMBM-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup\n"
      ],
      "metadata": {
        "id": "fNsU9gSzsiOM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7VMFggAT1nPr",
        "outputId": "0bfd6cbd-ddf0-4430-bed3-11584924101d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import the pytorch library into environment and check its version\n",
        "import os\n",
        "import torch\n",
        "print(\"Using torch\", torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7COOyFA1AbW-",
        "outputId": "bd8bb910-c066-4bd5-b1a9-21333a59f463"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using torch 2.1.0+cu118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install torch geometric\n",
        "import os\n",
        "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
        "  !pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-2.1.0+cu118.html\n",
        "  !pip install torch-sparse -f https://pytorch-geometric.com/whl/torch-2.1.0+cu118.html\n",
        "  !pip install torch-geometric\n",
        "  !pip install -q git+https://github.com/snap-stanford/deepsnap.git\n",
        "\n",
        "import torch_geometric\n",
        "torch_geometric.__version__"
      ],
      "metadata": {
        "id": "krMYyS_vr7cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 678
        },
        "outputId": "a587fe60-aafb-495e-eff7-3e2870c72a5f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://pytorch-geometric.com/whl/torch-2.1.0+cu118.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcu118/torch_scatter-2.1.2%2Bpt21cu118-cp310-cp310-linux_x86_64.whl (10.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.1.2+pt21cu118\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-2.1.0+cu118.html\n",
            "Collecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcu118/torch_sparse-0.6.18%2Bpt21cu118-cp310-cp310-linux_x86_64.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-sparse) (1.11.4)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-sparse) (1.23.5)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.18+pt21cu118\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.4.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.11.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2023.11.17)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.2.0)\n",
            "Installing collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.4.0\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for deepsnap (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.4.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "wmMf4WhBrjDF"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import os.path as osp\n",
        "import numpy as np\n",
        "from math import ceil\n",
        "import pandas as pd\n",
        "import copy\n",
        "from tqdm import tqdm, trange\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Linear\n",
        "\n",
        "from torch_geometric.datasets import UPFD\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.nn import GATConv, GCNConv, SAGEConv, global_max_pool, DenseSAGEConv, GINConv\n",
        "from torch_geometric.explain import Explainer, GNNExplainer\n",
        "from torch_geometric.transforms import ToUndirected\n",
        "from sklearn.metrics import f1_score, accuracy_score, roc_auc_score\n",
        "from torch_geometric.nn import global_mean_pool as gmp\n",
        "\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.data import DenseDataLoader\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.nn import DenseSAGEConv, dense_diff_pool\n",
        "from torch.utils.data import random_split\n",
        "from torch_geometric.nn import global_mean_pool\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GIN\n",
        "## Load Data"
      ],
      "metadata": {
        "id": "uhaorcPis4wg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(split):\n",
        "  \"\"\"\n",
        "  Load train, validation, and test data from the UPFD dataset in PyG. Concact node\n",
        "  features *profile* and *bert*, which are Twitter user's profile attributes and\n",
        "  historical tweets encoded through BERT respectively.\n",
        "\n",
        "  -------------------------------------\n",
        "  split: 'train', 'val', or 'test' for retrieving the respective portion of UPFD.\n",
        "\n",
        "  -------------------------------------\n",
        "  Return: PyG dataset object.\n",
        "  \"\"\"\n",
        "\n",
        "  data_profile =  UPFD('/tmp/test', \"gossipcop\", \"profile\", split, ToUndirected())\n",
        "  data_bert =  UPFD('/tmp/test', \"gossipcop\", \"bert\", split, ToUndirected())\n",
        "  data_profile.data.x = torch.cat((data_profile.data.x, data_bert.data.x),dim =1)\n",
        "\n",
        "  return data_profile"
      ],
      "metadata": {
        "id": "MwS27n4ms7jv"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve data\n",
        "train_data = load_data('train')\n",
        "test_data = load_data('test')\n",
        "val_data = load_data('val')\n",
        "\n",
        "# Prepare data loader for GNN\n",
        "train_loader = DataLoader(train_data, batch_size=128, shuffle=True)\n",
        "val_loader = DataLoader(val_data, batch_size=128, shuffle=False)\n",
        "test_loader = DataLoader(test_data, batch_size=128, shuffle=False)"
      ],
      "metadata": {
        "id": "YV9G0q8Cug9K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "542046d0-1532-4b69-a44a-2ef4eb210747"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://docs.google.com/uc?export=download&id=1VskhAQ92PrT4sWEKQ2v2-AJhEcpp4A81&confirm=t\n",
            "Extracting /tmp/test/gossipcop/raw/uc\n",
            "Processing...\n",
            "Done!\n",
            "Processing...\n",
            "Done!\n",
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for step, data in enumerate(train_loader):\n",
        "    print(f'Step {step + 1}, number of graphs in the current batch: {data.num_graphs}')\n",
        "    print(f'Step {step + 1}, number of nodes in the current batch: {data.num_nodes}')\n",
        "    print(f'Step {step + 1}, the graph id to which each node belongs is: {data.batch}')\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVGvftcqAvmH",
        "outputId": "79964e9b-b608-4aa8-835d-df2c58ed07f1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1, number of graphs in the current batch: 128\n",
            "Step 1, number of nodes in the current batch: 7273\n",
            "Step 1, the graph id to which each node belongs is: tensor([  0,   0,   0,  ..., 127, 127, 127])\n",
            "\n",
            "Step 2, number of graphs in the current batch: 128\n",
            "Step 2, number of nodes in the current batch: 6275\n",
            "Step 2, the graph id to which each node belongs is: tensor([  0,   0,   0,  ..., 127, 127, 127])\n",
            "\n",
            "Step 3, number of graphs in the current batch: 128\n",
            "Step 3, number of nodes in the current batch: 7469\n",
            "Step 3, the graph id to which each node belongs is: tensor([  0,   0,   0,  ..., 127, 127, 127])\n",
            "\n",
            "Step 4, number of graphs in the current batch: 128\n",
            "Step 4, number of nodes in the current batch: 7175\n",
            "Step 4, the graph id to which each node belongs is: tensor([  0,   0,   0,  ..., 127, 127, 127])\n",
            "\n",
            "Step 5, number of graphs in the current batch: 128\n",
            "Step 5, number of nodes in the current batch: 7336\n",
            "Step 5, the graph id to which each node belongs is: tensor([  0,   0,   0,  ..., 127, 127, 127])\n",
            "\n",
            "Step 6, number of graphs in the current batch: 128\n",
            "Step 6, number of nodes in the current batch: 7217\n",
            "Step 6, the graph id to which each node belongs is: tensor([  0,   0,   0,  ..., 127, 127, 127])\n",
            "\n",
            "Step 7, number of graphs in the current batch: 128\n",
            "Step 7, number of nodes in the current batch: 8830\n",
            "Step 7, the graph id to which each node belongs is: tensor([  0,   0,   0,  ..., 127, 127, 127])\n",
            "\n",
            "Step 8, number of graphs in the current batch: 128\n",
            "Step 8, number of nodes in the current batch: 7500\n",
            "Step 8, the graph id to which each node belongs is: tensor([  0,   0,   0,  ..., 127, 127, 127])\n",
            "\n",
            "Step 9, number of graphs in the current batch: 68\n",
            "Step 9, number of nodes in the current batch: 4407\n",
            "Step 9, the graph id to which each node belongs is: tensor([ 0,  0,  0,  ..., 67, 67, 67])\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yf6C8NPd0SN4",
        "outputId": "3ea60c0f-e024-455e-93a7-13bbf4fa258b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4407, 778])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GIN Architecture"
      ],
      "metadata": {
        "id": "iip4JQ1FsqEZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.nn import global_mean_pool\n",
        "\n",
        "class GINModel(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers):\n",
        "        super(GINModel, self).__init__()\n",
        "\n",
        "        # Input layer\n",
        "        self.embedding_layer = torch.nn.Linear(input_dim, hidden_dim)\n",
        "\n",
        "        # GIN layers\n",
        "        self.gin_layers = torch.nn.ModuleList([GINConv(torch.nn.Sequential(torch.nn.Linear(hidden_dim, hidden_dim), torch.nn.ReLU()))\n",
        "                                        for _ in range(num_layers)])\n",
        "\n",
        "        # Output layer\n",
        "        self.fc = torch.nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x, edge_index, batch):\n",
        "        x = F.relu(self.embedding_layer(x))\n",
        "\n",
        "        for conv in self.gin_layers:\n",
        "            x = F.relu(conv(x, edge_index))\n",
        "\n",
        "        # Global mean pooling\n",
        "        x = global_mean_pool(x, batch)\n",
        "\n",
        "        # Fully connected layer for classification\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n"
      ],
      "metadata": {
        "id": "aP7h923AvW9x"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GIN Model Training"
      ],
      "metadata": {
        "id": "XJFnruEMstcw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "parser add argument (optimizer, loss_fn, eval_metrics defualt accuracy)\n",
        "\"\"\"\n",
        "\n",
        "def train(model, data, optimizer, loss_fn):\n",
        "  \"\"\"\n",
        "  Train the model using given data, optimizer, and loss_fn\n",
        "  --------------------------------------\n",
        "  model: the model we specified\n",
        "  data: train data multiple batches of graphs, therefore needs to loop through each batch of graph\n",
        "        and add loss of each graph results.\n",
        "  \"\"\"\n",
        "  model.train()\n",
        "  out_loss = 0.0\n",
        "  for i, data in enumerate(data):\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data.x, data.edge_index, data.batch)\n",
        "    loss = loss_fn(out, data.y)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    out_loss += loss.item()\n",
        "\n",
        "  return out_loss\n"
      ],
      "metadata": {
        "id": "NjLmcvto-YDH"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GIN Model Performance"
      ],
      "metadata": {
        "id": "1cVyFOEEsvMD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def evaluate(model, loader, eval_metric = 'all'):\n",
        "  \"\"\"\n",
        "  Evaluate performance of the a GCN model based on the eval_metric.\n",
        "  \"\"\"\n",
        "\n",
        "  # Put model in evaluation mode\n",
        "  model.eval()\n",
        "\n",
        "  pred = []\n",
        "  label = []\n",
        "\n",
        "  for data in loader:\n",
        "    pred_y = model(data.x, data.edge_index, data.batch).argmax(dim=-1, keepdim=True).tolist()\n",
        "    pred.extend(pred_y)\n",
        "    label.extend(data.y)\n",
        "\n",
        "  acc = accuracy_score(label, pred)\n",
        "  f1 = f1_score(label, pred)\n",
        "  auc = roc_auc_score(label, pred)\n",
        "\n",
        "  return acc, f1, auc\n"
      ],
      "metadata": {
        "id": "yOHd2Bmlr5kR"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run GIN Model"
      ],
      "metadata": {
        "id": "9v8zDSSrVanT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parser = argparse.ArgumentParser()\n",
        "\n",
        "parser.add_argument('--seed', type=int, default=777, help='random seed')\n",
        "parser.add_argument('--device', type=str, default='cpu', help='specify cuda devices')\n",
        "\n",
        "# hyper-parameters\n",
        "parser.add_argument('--dataset', type=str, default='gossipcop', help='[politifact, gossipcop]')\n",
        "parser.add_argument('--batch_size', type=int, default=128, help='batch size')\n",
        "parser.add_argument('--lr', type=float, default=0.01, help='learning rate')\n",
        "parser.add_argument('--weight_decay', type=float, default=0.01, help='weight decay')\n",
        "parser.add_argument('--hidden_dim', type=int, default=128, help='hidden size')\n",
        "parser.add_argument('--dropout', type=float, default=0.0, help='dropout ratio')\n",
        "parser.add_argument('--epochs', type=int, default=100, help='maximum number of epochs')\n",
        "parser.add_argument('--concat', type=bool, default=True, help='whether concat news embedding and graph embedding')\n",
        "parser.add_argument('--multi_gpu', type=bool, default=False, help='multi-gpu mode')\n",
        "parser.add_argument('--feature', type=str, default='bert', help='feature type, [profile, spacy, bert, content]')\n",
        "parser.add_argument('--model', type=str, default='sage', help='model type, [gcn, gat, sage]')\n",
        "parser.add_argument('--eval', type = str, default = 'accuracy', help = 'evaluation type')\n",
        "parser.add_argument('--num_layers', type=str, default = 2, help = 'num of GNN layers')\n",
        "\n",
        "args, _ = parser.parse_known_args()\n",
        "torch.manual_seed(args.seed)\n",
        "if torch.cuda.is_available():\n",
        "\ttorch.cuda.manual_seed(args.seed)\n",
        "\n",
        "args.num_classes = train_data.num_classes\n",
        "args.num_features = train_data.num_features\n",
        "\n",
        "model = GINModel(args.num_features, args.hidden_dim, args.num_classes, 2)\n",
        "model = model.to(args.device)"
      ],
      "metadata": {
        "id": "JL_PzguVVlKU"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#if __name__ == '__main__':\n",
        "\n",
        "best_model = None\n",
        "best_val_value = 0\n",
        "\n",
        "evaluator = args.eval\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr, weight_decay = args.weight_decay)\n",
        "loss_fn = F.nll_loss\n",
        "\n",
        "# Lists to store values for plotting\n",
        "train_losses = []\n",
        "train_eval_values = []\n",
        "val_eval_values = []\n",
        "\n",
        "model.train()\n",
        "for epoch in tqdm(range(1, args.epochs)):\n",
        "  loss = train(model, train_loader, optimizer, loss_fn)\n",
        "  train_eval = evaluate(model, train_loader)\n",
        "  val_eval = evaluate(model, val_loader)\n",
        "\n",
        "  # Append values for plotting\n",
        "  train_losses.append(loss)\n",
        "  train_eval_values.append(train_eval[0])\n",
        "  val_eval_values.append(val_eval[0])\n",
        "\n",
        "  if val_eval[0] > best_val_value:\n",
        "    best_val_value = val_eval[0]\n",
        "    best_model = copy.deepcopy(model)\n",
        "  print(f'loss_train:{loss:.4f}, train_{evaluator}:{train_eval[0]:.4f}, val_{evaluator}:{val_eval[0]:.4f} ')\n",
        "acc, f1, auc = evaluate(best_model, test_loader)\n",
        "print(f'Test results: acc {acc:.4f}, f1 score: {f1:.4f}, auc: {auc:.4f}' )\n"
      ],
      "metadata": {
        "id": "Uv70cooqVcJ9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "outputId": "25a2cebd-ab3e-43be-ea8c-7a4c00e4b601"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/99 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-932f4757faee>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m   \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m   \u001b[0mtrain_eval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m   \u001b[0mval_eval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-5efbe37ffd9d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, data, optimizer, loss_fn)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2727\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2728\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2729\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss_nd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2730\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Expected input batch_size (128) to match target batch_size (130)."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "  # Plot Loss\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.plot(train_losses, label='Train Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Loss')\n",
        "plt.legend()\n",
        "\n",
        "  # Plot Accuracy\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.plot(train_eval_values, label='Train Accuracy')\n",
        "plt.plot(val_eval_values, label='Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "  # Assuming 'evaluate' function returns acc, f1, auc\n",
        "acc, f1, auc = evaluate(best_model, test_loader)\n",
        "\n",
        "  # Plot F1 Score and AUC\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.bar(['Accuracy', 'F1 Score', 'AUC'], [acc, f1, auc])\n",
        "plt.ylabel('Metrics')\n",
        "plt.title('Test Metrics')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fVQxXbhfvpQG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}