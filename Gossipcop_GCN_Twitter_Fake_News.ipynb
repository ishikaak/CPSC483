{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### GCN implementation for Fake News Detection on Gossipcop dataset"
      ],
      "metadata": {
        "id": "DwRMdI3yMBM-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup\n"
      ],
      "metadata": {
        "id": "fNsU9gSzsiOM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7VMFggAT1nPr",
        "outputId": "67e85a57-dccd-4929-b9dd-c7b6e4668397"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import the pytorch library into environment and check its version\n",
        "import os\n",
        "import torch\n",
        "print(\"Using torch\", torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7COOyFA1AbW-",
        "outputId": "9235d42c-08f7-4ac1-f3e6-aeaac4278d63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using torch 2.1.0+cu118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install torch geometric\n",
        "import os\n",
        "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
        "  !pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-2.1.0+cu118.html\n",
        "  !pip install torch-sparse -f https://pytorch-geometric.com/whl/torch-2.1.0+cu118.html\n",
        "  !pip install torch-geometric\n",
        "  !pip install -q git+https://github.com/snap-stanford/deepsnap.git\n",
        "\n",
        "import torch_geometric\n",
        "torch_geometric.__version__"
      ],
      "metadata": {
        "id": "krMYyS_vr7cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f255302-f7bd-4f9d-935e-7a74043c0149"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://pytorch-geometric.com/whl/torch-2.1.0+cu118.html\n",
            "Requirement already satisfied: torch-scatter in /usr/local/lib/python3.10/dist-packages (2.1.2+pt21cu118)\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-2.1.0+cu118.html\n",
            "Requirement already satisfied: torch-sparse in /usr/local/lib/python3.10/dist-packages (0.6.18+pt21cu118)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-sparse) (1.11.4)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-sparse) (1.23.5)\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.10/dist-packages (2.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.11.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2023.11.17)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.2.0)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.4.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wmMf4WhBrjDF"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import os.path as osp\n",
        "import numpy as np\n",
        "from math import ceil\n",
        "import pandas as pd\n",
        "import copy\n",
        "from tqdm import tqdm, trange\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Linear\n",
        "\n",
        "from torch_geometric.datasets import UPFD\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.nn import GATConv, GCNConv, SAGEConv, global_max_pool, DenseSAGEConv\n",
        "from torch_geometric.explain import Explainer, GNNExplainer\n",
        "from torch_geometric.transforms import ToUndirected\n",
        "from sklearn.metrics import f1_score, accuracy_score, roc_auc_score\n",
        "from torch_geometric.nn import global_mean_pool as gmp\n",
        "\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.data import DenseDataLoader\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.nn import DenseSAGEConv, dense_diff_pool\n",
        "from torch.utils.data import random_split\n",
        "import matplotlib.pyplot as plt\n",
        "from torch_geometric.nn import global_mean_pool"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GCN\n",
        "## Load Data"
      ],
      "metadata": {
        "id": "uhaorcPis4wg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(split):\n",
        "  \"\"\"\n",
        "  Load train, validation, and test data from the UPFD dataset in PyG. Concact node\n",
        "  features *profile* and *bert*, which are Twitter user's profile attributes and\n",
        "  historical tweets encoded through BERT respectively.\n",
        "\n",
        "  -------------------------------------\n",
        "  split: 'train', 'val', or 'test' for retrieving the respective portion of UPFD.\n",
        "\n",
        "  -------------------------------------\n",
        "  Return: PyG dataset object.\n",
        "  \"\"\"\n",
        "\n",
        "  data_profile =  UPFD('/tmp/test', \"gossipcop\", \"profile\", split, ToUndirected())\n",
        "  data_bert =  UPFD('/tmp/test', \"gossipcop\", \"bert\", split, ToUndirected())\n",
        "  data_profile.data.x = torch.cat((data_profile.data.x, data_bert.data.x),dim =1)\n",
        "\n",
        "  return data_profile"
      ],
      "metadata": {
        "id": "MwS27n4ms7jv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve data\n",
        "train_data = load_data('train')\n",
        "test_data = load_data('test')\n",
        "val_data = load_data('val')\n",
        "\n",
        "# Prepare data loader for GNN\n",
        "train_loader = DataLoader(train_data, batch_size=128, shuffle=True)\n",
        "val_loader = DataLoader(val_data, batch_size=128, shuffle=False)\n",
        "test_loader = DataLoader(test_data, batch_size=128, shuffle=False)"
      ],
      "metadata": {
        "id": "YV9G0q8Cug9K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea059dda-aa52-49ed-d36d-ef5eebc83ba4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for step, data in enumerate(train_loader):\n",
        "    print(f'Step {step + 1}, number of graphs in the current batch: {data.num_graphs}')\n",
        "    print(f'Step {step + 1}, number of nodes in the current batch: {data.num_nodes}')\n",
        "    print(f'Step {step + 1}, the graph id to which each node belongs is: {data.batch}')\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVGvftcqAvmH",
        "outputId": "54286db4-b3f5-4ff5-f646-6fb4c7437b45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1, number of graphs in the current batch: 128\n",
            "Step 1, number of nodes in the current batch: 7349\n",
            "Step 1, the graph id to which each node belongs is: tensor([  0,   0,   0,  ..., 127, 127, 127])\n",
            "\n",
            "Step 2, number of graphs in the current batch: 128\n",
            "Step 2, number of nodes in the current batch: 8649\n",
            "Step 2, the graph id to which each node belongs is: tensor([  0,   0,   0,  ..., 127, 127, 127])\n",
            "\n",
            "Step 3, number of graphs in the current batch: 128\n",
            "Step 3, number of nodes in the current batch: 7022\n",
            "Step 3, the graph id to which each node belongs is: tensor([  0,   0,   0,  ..., 127, 127, 127])\n",
            "\n",
            "Step 4, number of graphs in the current batch: 128\n",
            "Step 4, number of nodes in the current batch: 7612\n",
            "Step 4, the graph id to which each node belongs is: tensor([  0,   0,   0,  ..., 127, 127, 127])\n",
            "\n",
            "Step 5, number of graphs in the current batch: 128\n",
            "Step 5, number of nodes in the current batch: 6995\n",
            "Step 5, the graph id to which each node belongs is: tensor([  0,   0,   0,  ..., 127, 127, 127])\n",
            "\n",
            "Step 6, number of graphs in the current batch: 128\n",
            "Step 6, number of nodes in the current batch: 6644\n",
            "Step 6, the graph id to which each node belongs is: tensor([  0,   0,   0,  ..., 127, 127, 127])\n",
            "\n",
            "Step 7, number of graphs in the current batch: 128\n",
            "Step 7, number of nodes in the current batch: 7965\n",
            "Step 7, the graph id to which each node belongs is: tensor([  0,   0,   0,  ..., 127, 127, 127])\n",
            "\n",
            "Step 8, number of graphs in the current batch: 128\n",
            "Step 8, number of nodes in the current batch: 7436\n",
            "Step 8, the graph id to which each node belongs is: tensor([  0,   0,   0,  ..., 127, 127, 127])\n",
            "\n",
            "Step 9, number of graphs in the current batch: 68\n",
            "Step 9, number of nodes in the current batch: 3810\n",
            "Step 9, the graph id to which each node belongs is: tensor([ 0,  0,  0,  ..., 67, 67, 67])\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjrNxURL0MK6",
        "outputId": "686ee0a1-188f-4bd8-b5e1-968d755ad3cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3810, 778])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GCN Architecture"
      ],
      "metadata": {
        "id": "iip4JQ1FsqEZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class GCN(torch.nn.Module):\n",
        "  def __init__(self, args):\n",
        "    super(GCN, self).__init__()\n",
        "\n",
        "    self.GCNConv1 = GCNConv(args.num_features, args.hidden_dim) #first GCNConv module\n",
        "    self.batchnorm = torch.nn.BatchNorm1d(args.hidden_dim)\n",
        "    self.GCNConv2 = GCNConv(args.hidden_dim, args.hidden_dim) #second GCNConv module\n",
        "    self.Linear = torch.nn.Linear(args.hidden_dim, args.num_classes) #linear function\n",
        "    self.relu = torch.nn.ReLU() #relu function\n",
        "\n",
        "  def forward(self, x, edge_index, batch):\n",
        "    output = None\n",
        "    output = self.GCNConv1(x, edge_index)\n",
        "    output = self.batchnorm(output)\n",
        "    output = self.relu(output)\n",
        "    output = self.GCNConv2(output, edge_index)\n",
        "    output = self.batchnorm(output)\n",
        "    output = global_mean_pool(output, batch)\n",
        "    output = self.Linear(output)\n",
        "    output = F.log_softmax(output, dim=-1)\n",
        "\n",
        "    return output\n"
      ],
      "metadata": {
        "id": "aP7h923AvW9x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.batch.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Y-fnOiM0Ija",
        "outputId": "d9095edb-1dba-471a-9c1e-5122c1acfd46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3810])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GCN Model Training"
      ],
      "metadata": {
        "id": "XJFnruEMstcw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "parser add argument (optimizer, loss_fn, eval_metrics defualt accuracy)\n",
        "\"\"\"\n",
        "\n",
        "def train(model, data, optimizer, loss_fn):\n",
        "  \"\"\"\n",
        "  Train the model using given data, optimizer, and loss_fn\n",
        "  --------------------------------------\n",
        "  model: the model we specified\n",
        "  data: train data multiple batches of graphs, therefore needs to loop through each batch of graph\n",
        "        and add loss of each graph results.\n",
        "  \"\"\"\n",
        "  model.train()\n",
        "  out_loss = 0.0\n",
        "  for i, data in enumerate(data):\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data.x, data.edge_index, data.batch)\n",
        "    loss = loss_fn(out, data.y)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    out_loss += loss.item()\n",
        "\n",
        "  return out_loss\n"
      ],
      "metadata": {
        "id": "NjLmcvto-YDH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9q8ueHmyy09",
        "outputId": "853d62cb-b1d1-4fb3-da72-84b1fc945173"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([69])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GCN Model Performance"
      ],
      "metadata": {
        "id": "1cVyFOEEsvMD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def evaluate(model, loader, eval_metric = 'all'):\n",
        "  \"\"\"\n",
        "  Evaluate performance of the a GCN model based on the eval_metric.\n",
        "  \"\"\"\n",
        "\n",
        "  # Put model in evaluation mode\n",
        "  model.eval()\n",
        "\n",
        "  pred = []\n",
        "  label = []\n",
        "\n",
        "  for data in loader:\n",
        "    pred_y = model(data.x, data.edge_index, data.batch).argmax(dim=-1, keepdim=True).tolist()\n",
        "    pred.extend(pred_y)\n",
        "    label.extend(data.y)\n",
        "\n",
        "  acc = accuracy_score(label, pred)\n",
        "  f1 = f1_score(label, pred)\n",
        "  auc = roc_auc_score(label, pred)\n",
        "\n",
        "  return acc, f1, auc\n"
      ],
      "metadata": {
        "id": "yOHd2Bmlr5kR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run GCN Model"
      ],
      "metadata": {
        "id": "9v8zDSSrVanT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parser = argparse.ArgumentParser()\n",
        "\n",
        "parser.add_argument('--seed', type=int, default=777, help='random seed')\n",
        "parser.add_argument('--device', type=str, default='cpu', help='specify cuda devices')\n",
        "\n",
        "# hyper-parameters\n",
        "parser.add_argument('--dataset', type=str, default='gossipcop', help='[politifact, gossipcop]')\n",
        "parser.add_argument('--batch_size', type=int, default=128, help='batch size')\n",
        "parser.add_argument('--lr', type=float, default=0.01, help='learning rate')\n",
        "parser.add_argument('--weight_decay', type=float, default=0.01, help='weight decay')\n",
        "parser.add_argument('--hidden_dim', type=int, default=128, help='hidden size')\n",
        "parser.add_argument('--dropout', type=float, default=0.0, help='dropout ratio')\n",
        "parser.add_argument('--epochs', type=int, default=100, help='maximum number of epochs')\n",
        "parser.add_argument('--concat', type=bool, default=True, help='whether concat news embedding and graph embedding')\n",
        "parser.add_argument('--multi_gpu', type=bool, default=False, help='multi-gpu mode')\n",
        "parser.add_argument('--feature', type=str, default='bert', help='feature type, [profile, spacy, bert, content]')\n",
        "parser.add_argument('--model', type=str, default='sage', help='model type, [gcn, gat, sage]')\n",
        "parser.add_argument('--eval', type = str, default = 'accuracy', help = 'evaluation type')\n",
        "parser.add_argument('--num_layers', type=str, default = 2, help = 'num of GNN layers')\n",
        "\n",
        "args, _ = parser.parse_known_args()\n",
        "torch.manual_seed(args.seed)\n",
        "if torch.cuda.is_available():\n",
        "\ttorch.cuda.manual_seed(args.seed)\n",
        "\n",
        "args.num_classes = train_data.num_classes\n",
        "args.num_features = train_data.num_features\n",
        "\n",
        "model = GCN(args)\n",
        "model = model.to(args.device)"
      ],
      "metadata": {
        "id": "JL_PzguVVlKU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#if __name__ == '__main__':\n",
        "\n",
        "best_model = None\n",
        "best_val_value = 0\n",
        "\n",
        "evaluator = args.eval\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr, weight_decay = args.weight_decay)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Lists to store values for plotting\n",
        "train_losses = []\n",
        "train_eval_values = []\n",
        "val_eval_values = []\n",
        "\n",
        "model.train()\n",
        "for epoch in tqdm(range(1, args.epochs)):\n",
        "  loss = train(model, train_loader, optimizer, loss_fn)\n",
        "  train_eval = evaluate(model, train_loader)\n",
        "  val_eval = evaluate(model, val_loader)\n",
        "\n",
        "  # Append values for plotting\n",
        "  train_losses.append(loss)\n",
        "  train_eval_values.append(train_eval[0])\n",
        "  val_eval_values.append(val_eval[0])\n",
        "\n",
        "  if val_eval[0] > best_val_value:\n",
        "    best_val_value = val_eval[0]\n",
        "    best_model = copy.deepcopy(model)\n",
        "  print(f'loss_train:{loss:.4f}, train_{evaluator}:{train_eval[0]:.4f}, val_{evaluator}:{val_eval[0]:.4f} ')\n",
        "acc, f1, auc = evaluate(best_model, test_loader)\n",
        "print(f'Test results: acc {acc:.4f}, f1 score: {f1:.4f}, auc: {auc:.4f}' )\n",
        "\n"
      ],
      "metadata": {
        "id": "Uv70cooqVcJ9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "outputId": "3d4c20ff-2847-4154-c97a-8892a7a1d4a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/99 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-072b5e0e62ca>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m   \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m   \u001b[0mtrain_eval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m   \u001b[0mval_eval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-53-5efbe37ffd9d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, data, optimizer, loss_fn)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1179\u001b[0;31m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[1;32m   1180\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m                                label_smoothing=self.label_smoothing)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3051\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3052\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3053\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3055\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Expected input batch_size (128) to match target batch_size (129)."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "  # Plot Loss\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.plot(train_losses, label='Train Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Loss')\n",
        "plt.legend()\n",
        "\n",
        "  # Plot Accuracy\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.plot(train_eval_values, label='Train Accuracy')\n",
        "plt.plot(val_eval_values, label='Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "  # Assuming 'evaluate' function returns acc, f1, auc\n",
        "acc, f1, auc = evaluate(best_model, test_loader)\n",
        "\n",
        "  # Plot F1 Score and AUC\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.bar(['Accuracy', 'F1 Score', 'AUC'], [acc, f1, auc])\n",
        "plt.ylabel('Metrics')\n",
        "plt.title('Test Metrics')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CZSgxPcGxCaM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}